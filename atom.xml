<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://fujianfei1991.github.io</id>
    <title>学习记录</title>
    <updated>2022-02-08T13:28:27.009Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://fujianfei1991.github.io"/>
    <link rel="self" href="https://fujianfei1991.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://fujianfei1991.github.io/images/avatar.png</logo>
    <icon>https://fujianfei1991.github.io/favicon.ico</icon>
    <rights>All rights reserved 2022, 学习记录</rights>
    <entry>
        <title type="html"><![CDATA[如何在一个github仓库存放多个项目]]></title>
        <id>https://fujianfei1991.github.io/post/ru-he-zai-yi-ge-github-cang-ku-cun-fang-duo-ge-xiang-mu/</id>
        <link href="https://fujianfei1991.github.io/post/ru-he-zai-yi-ge-github-cang-ku-cun-fang-duo-ge-xiang-mu/">
        </link>
        <updated>2020-10-22T07:35:20.000Z</updated>
        <content type="html"><![CDATA[<p>最近做了一个项目，涉及到web端、后端、微信小程序、APP等多个程序，如果每个端都新起一个项目的话管理起来实在是费劲，遂有了下面的这段文字，记录一下操作方式</p>
<h2 id="首先">首先</h2>
<p>去github上面创建一个仓库，随你怎么建立，不做此处不做说明</p>
<h2 id="本地项目a">本地项目A</h2>
<p>我们在本地建立了一个项目A，如下：</p>
<pre><code>$ mkdir a
$ cd a
$ touch a_file.txt
# 初始化 git 
$ git init
$ git add .
$ git commit -a -m &quot;a_file&quot;
# 将本地仓库与远程仓库关联起来
$ git remote add origin  https://github.com/username/repository_name.git
# 注意这里的基础分支 master 
$ git push -u origin master      
</code></pre>
<p>如果之前没有把用户信息添加进去的话就需要验证一下用户</p>
<blockquote>
<p>初次提交的时候需要设置用户名与邮箱<br>
git config --global user.email &quot;email&quot;<br>
git config --global user.name &quot;username&quot;<br>
方法一：你可以去.git/config 文件里面添加一下你的github的用户信息</p>
</blockquote>
<pre><code>[remote &quot;origin&quot;]
url  =  https://github.com/username/repository_name.git      # 修改前
url  =  https://username:password@github.com/username/repository_name.git    # 修改后
这里把用户名跟密码都补充上去
</code></pre>
<p>方法二：直接在提交的时候输入用户名密码，如下：</p>
<pre><code>Username for 'https://github.com':    username
Password for 'https://fujianfei1991@github.com':  password
</code></pre>
<p>鉴权搞定了之后再次去提交一下项目就可以了</p>
<pre><code>$ git push -u origin master
</code></pre>
<p>到此项目A就搞定了，代码也提交到github上面去了，可以去验证一下</p>
<p>接下来就是搞定项目B了</p>
<h2 id="项目b">项目B</h2>
<p>我们在十万八千里之外的一个电脑上面建立了一个项目B，如下：</p>
<pre><code>$ mkdir b
$ cd b
$ touch b_file.txt
$ git init    # 项目初始化
$ git checkout --orphan test       # 这里有个新词   orphan  后面会说明的
$ git add .
$ git commit -a -m 'b分支的代码'
# 将本地仓库与远程仓库关联起来
$ git remote add origin  https://github.com/username/repository_name.git
# 注意这里的基础分支 master 
$ git push -u origin test:test        # 将本地的test分支提交到github上面的test分支
</code></pre>
<p>上面的 orphan 就是创建一个无历史的分支，跟创建普通分支不同的是，他不会根据默认的分支(master)来创建新的分支<br>
此时，再去github上面查看的时候就会发现惊喜，master分支与test分支完全不一样，这样就实现了一个仓库管理多个项目的目的</p>
<p>有些时候，你可能还需要对不同的项目再去创建多个分支，这个时候在本地创建新分支的时候就需要去根据原始分支来创建了</p>
<pre><code>$ git checkout -b test_new test      # 根据test分支来创建新分支
</code></pre>
<p>一顿操作之后，再次提交，去github上面查看，这个时候test_new分支的内容就继承自test分支，是项目B的内容，而原来的master分支里面的就是项目A的内容</p>
<p>Game Over</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微信小程序蓝牙控制注意事项]]></title>
        <id>https://fujianfei1991.github.io/post/wei-xin-xiao-cheng-xu-lan-ya-kong-zhi/</id>
        <link href="https://fujianfei1991.github.io/post/wei-xin-xiao-cheng-xu-lan-ya-kong-zhi/">
        </link>
        <updated>2020-09-08T07:55:39.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>注：需要手机先开启蓝牙才能使用</p>
</blockquote>
<h3 id="1-关于指令问题">1、关于指令问题</h3>
<pre><code>A：超过20个字符的指令需要做分包处理
B：发送的数据为16进制的buffer数据
C：对于arrayBuffer的理可以看下如下文章 
    [https://blog.csdn.net/hunhun1122/article/details/82995787] javascript ArrayBuffer浅析
</code></pre>
<h4 id="转码如下">转码如下</h4>
<pre><code class="language-javascript">var hex = &quot;&lt;B452b989|1|0000008&gt;&quot;
let val = &quot;&quot;
for (let i = 0; i &lt; hex.length; i++) {
    if (val === '') {
        val = hex.charCodeAt(i).toString(16)
    } else {
        val += ',' + hex.charCodeAt(i).toString(16)
    }
}
console.log(val)
var typedArray = new Uint8Array(val.match(/[\da-f]{2}/gi).map(function (h) {
    return parseInt(h, 16)
}))
console.log(typedArray)
var buffer1 = typedArray.buffer
// 这里的最后的buffer1 就是需要写到蓝牙设备里面的指令
</code></pre>
<h3 id="2-关于蓝牙设备mac地址的获取">2、关于蓝牙设备MAC地址的获取</h3>
<p>分Android跟IOS两种情况<br>
A：Android系统的微信小程序通过 <code>wx.getBluetoothDevices</code> 获取的 <code>deviceId</code> 就是设备的蓝牙MAC地址<br>
B：苹果IOS系统的微信小程序通过 <code>wx.getBluetoothDevices</code>  获取的 <code>deviceId</code> 是UUID，这个时候就需要根据  <code>wx.getBluetoothDevices</code> 返回的 <code>advertisData</code> 来生成MAC地址，这个 <code>advertisData</code> 有时候是为空的，所以我们在保存设备信息的时候IOS系统下的 <code>deviceId</code> 也需要保存一份，使用 <code>advertisData</code> 转MAC的方式如下</p>
<pre><code class="language-javascript">let list = res.devices
for (var i = 0; i &lt; list.length; i++) {
    if (list[i].advertisData != null) {//判断对象是否为null，advertisData不一定有
        //重点 根据advertisData 取出mac进行拼接
        let bf = list[i].advertisData.slice(2, 10);
        let mac = Array.prototype.map.call(new Uint8Array(bf), x =&gt; ('00' + x.toString(16)).slice(-2)).join(':');
        console.log(mac.toUpperCase());
        //判断mac是否为服务器传入mac
        if (mac.toUpperCase() == '3C:A3:08:BA:45:35') {
            that.setData({
                deviceId: list[i].deviceId
            });
            console.log('deviceId:' + that.data.deviceId);
        }
        console.log(list[i]);
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[nginx + php-fpm 调优]]></title>
        <id>https://fujianfei1991.github.io/post/nginx-php-fpm-diao-you/</id>
        <link href="https://fujianfei1991.github.io/post/nginx-php-fpm-diao-you/">
        </link>
        <updated>2020-08-06T07:21:54.000Z</updated>
        <content type="html"><![CDATA[<h2 id="进程通信方式">进程通信方式</h2>
<blockquote>
<p>nginx 和 php-fpm 的进程间通信有两种方式<br>
A：基于 TCP 的，IP加端口的方式，可以跨服务器<br>
B：是 UNIX Domain Socket，不经过网络，只能用于 Nginx 跟 PHP-FPM 都在同一服务器的场景，具体使用哪种取决于nginx和php-fpm的配置</p>
</blockquote>
<pre><code># 方式A
php-fpm.conf: listen = 127.0.0.1:9000
nginx.conf: fastcgi_pass 127.0.0.1:9000;
# 方式B
php-fpm.conf: listen = /tmp/php-fpm.sock
nginx.conf: fastcgi_pass unix:/tmp/php-fpm.sock;
</code></pre>
<p>由此可以看出，当使用单机的情况下，使用UNIX Domain Socket 的方式更好，涉及到多台机器转发的时候，使用TCP进行网络通信的方式才可以<br>
UNIX Domain Socket 在面对高并发的的时候不太稳定，会出现大量的502错误，这里是由于内核的最大连接数导致的<br>
错误信息如下：</p>
<pre><code>connect() to unix:/tmp/php-cgi.sock failed (11: Resource temporarily unavailable) while connecting to upstream
</code></pre>
<h3 id="优化方法">优化方法</h3>
<p>查看系统内核参数大小：</p>
<pre><code>[root@izbp1afvt32y9uri4c7x4tz ~]# cat /proc/sys/net/core/somaxconn
128
</code></pre>
<p>根据自己的情况来调整内核参数</p>
<pre><code># /etc/sysctl.conf
net.unix.max_dgram_qlen = 4096
net.core.netdev_max_backlog = 4096
net.core.somaxconn = 4096
</code></pre>
<p>查看80端口允许连接数大小</p>
<pre><code>[root@izbp1afvt32y9uri4c7x4tz ~]# cat /proc/sys/net/core/somaxconn
Netid State      Recv-Q Send-Q     Local Address:Port                    Peer Address:Port
tcp   LISTEN     0      128                   *:80                                 *:*
</code></pre>
<p>修改 nginx  和php-fpm 的 backlog大小，nginx默认511</p>
<pre><code># nginx.conf
server{
  listen 80 default backlog=1024;
}
# php-fpm.conf
listen.backlog = 1024
</code></pre>
<p>调整之后 UNIX Domain Socket 在面对大量并发的时候也可以稳定运行了<br>
关于 php-fpm 和 php配置的调整可以看下下面的文章</p>
<blockquote>
<p>https://juejin.im/post/6844903849132556296<br>
https://learnku.com/articles/18782<br>
https://blog.thinkphp.cn/843679</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[iptables + ipset 屏蔽禁止国外IP访问]]></title>
        <id>https://fujianfei1991.github.io/post/iptables-ipset-ping-bi-jin-zhi-guo-wai-ip-fang-wen/</id>
        <link href="https://fujianfei1991.github.io/post/iptables-ipset-ping-bi-jin-zhi-guo-wai-ip-fang-wen/">
        </link>
        <updated>2020-07-31T03:11:39.000Z</updated>
        <content type="html"><![CDATA[<p>起初遇到这个问题是因为 <code>freeswitch</code> 盗打的出现，频繁的盗打影响呼叫中心的使用。这里很多盗打的IP来源就是国外的IP地址，那么禁止国外的IP地址就可以解决问题了</p>
<blockquote>
<p>ipset是iptables的扩展,它允许你创建 匹配整个地址集合的规则。而不像普通的iptables链只能单IP匹配, ip集合存储在带索引的数据结构中,这种结构即时集合比较大也可以进行高效的查找，除了一些常用的情况,比如阻止一些危险主机访问本机，从而减少系统资源占用或网络拥塞,IPsets也具备一些新防火墙设计方法,并简化了配置.官网：http://ipset.netfilter.org/</p>
</blockquote>
<p>这里就是利用<code>ipset</code>来将国内的IP收集起来，只开发国内的IP地址</p>
<h2 id="安装-ipset">安装 IPSET</h2>
<p>当前环境如下：</p>
<pre><code>[root@izbp1afvt32y9uri4c7x4tz ~]# cat /etc/redhat-release 
CentOS Linux release 7.8.2003 (Core)

$ yum install ipset     # 安装
</code></pre>
<h4 id="创建-ip集合">创建 IP集合</h4>
<pre><code>$ ipset create mainland hash:net maxelem 65536
mainland : 这个就是当前集合的名称
hash : 表示以hash方式存储信息
net :  指定可以往集合中添加IP段或者IP地址
maxelem : 表示可以存储最大的条目数量，这里就是 65536
</code></pre>
<h4 id="编写脚本自动更新数据到-ip-集合当中">编写脚本自动更新数据到 IP 集合当中</h4>
<p>保存在 <code>/home/mainland.sh</code></p>
<pre><code>#!/usr/bin/env bash
wget --no-check-certificate -O- 'http://ftp.apnic.net/apnic/stats/apnic/delegated-apnic-latest' | awk -F\| '/CN\|ipv4/ { printf(&quot;%s/%d\n&quot;, $4, 32-log($5)/log(2)) }' &gt; /home/mainland.txt
ipset flush mainland
while read ip; do
    ipset add mainland $ip
done &lt; /home/mainland.txt
ipset save chnroute &gt; /home/mainland.conf
</code></pre>
<p>可以设置一个定时任务，不断的去更新IP集合</p>
<h2 id="配置-iptables-限制访问">配置 <code>iptables</code> 限制访问</h2>
<p>配置某个端口需要禁止国外访问的话，我们就需要在 <code>iptables</code> 当中禁止了端口的访问，并且针对 ipset 的集合开放接口，以 <code>8090</code> 端口为例</p>
<pre><code>iptables -A INPUT -m set --match-set mainland src -p tcp --dport 8090 -j ACCEPT
iptables -A INPUT -m set --match-set mainland src -p udp --dport 8090 -j ACCEPT
iptables -A INPUT -p tcp --dport 8090 -j DROP
iptables -A INPUT -p udp --dport 8090 -j DROP
</code></pre>
<p>保存之后，重载一下 <code>iptables</code> 让新规则生效</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Dockerfile 创建镜像]]></title>
        <id>https://fujianfei1991.github.io/post/dockerfile-chuang-jian-jing-xiang/</id>
        <link href="https://fujianfei1991.github.io/post/dockerfile-chuang-jian-jing-xiang/">
        </link>
        <updated>2020-07-28T07:57:52.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>使用Dockerfile 来构建镜像的时候必须要基于一个基础镜像来构建，这也就是每个Dockerfile文件的开头必须是 FROM 指令的原因<br>
#Base image<br>
FROM centos</p>
</blockquote>
<p>设置docker主机访问网络</p>
<pre><code># /etc/docker/daemon.json
&quot;dns&quot;: [&quot;100.100.2.136&quot;,&quot;100.100.2.138&quot;]

# 上面的值在 /etc/resolv.conf当中查询
</code></pre>
<h2 id="当前使用nginx-来做样例做说明">当前使用nginx 来做样例做说明</h2>
<p>在写 <code>Dockerfile</code>的时候有个前提就是必须会使用或者安装指定的软件等，不然是写不出来的<br>
下面是<code>nginx</code>的<code>Dockerfile</code> 文件内容</p>
<pre><code># 基础镜像
FROM centos

# 作者信息
MAINTAINER 13260674703@163.com

# 将安装目录解压到 &quot;/usr/local/src&quot; 目录，如果是&quot;.zip&quot;文件的话，ADD指令是无法解压的
ADD nginx-1.16.1.tar.gz /usr/local/src

# 安装相关依赖以及添加用户
RUN yum install -y gcc gcc-c++ glibc make autoconf openssl openssl-devel 
RUN yum install -y libxslt-devel -y gd gd-devel pcre pcre-devel
RUN useradd -M -s /sbin/nologin nginx

# 转到nginx目录
WORKDIR /usr/local/src/nginx-1.16.1

# 执行安装指令
RUN ./configure --user=nginx --group=nginx --prefix=/usr/local/nginx --with-file-aio --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_xslt_module --with-http_image_filter_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_auth_request_module --with-http_random_index_module --with-http_secure_link_module --with-http_degradation_module --with-http_stub_status_module &amp;&amp; make &amp;&amp; make install

# nginx是否以守护进程运行，是否让nignx运行于后台；调试时应该为off，使得所有信息直接输出在控制台
RUN echo &quot;daemon off;&quot; &gt;&gt; /usr/local/nginx/conf/nginx.conf

# 设置环境变量
ENV PATH /usr/local/nginx/sbin:$PATH

# 定义向外暴露的端口号,多个端口用空格做间隔,启动容器的时候&quot;-p&quot;需要使用此端向外端映射.
EXPOSE 80

# 定义控制台的运行命令
CMD [&quot;nginx&quot;]
</code></pre>
<blockquote>
<p>Dockerfile 其他详细命令参考：https://docs.docker.com/engine/reference/builder/</p>
</blockquote>
<h2 id="构建镜像">构建镜像</h2>
<p>在<code>Dockerfile</code> 文件存放目录，执行构建操作</p>
<blockquote>
<p>最后的 . 代表本次执行的上下文路径</p>
</blockquote>
<pre><code>$ docker build -t nginx:test .
</code></pre>
<p><img src="https://fujianfei1991.github.io/post-images/1595987633967.jpg" alt="" loading="lazy"><br>
以上显示，说明已经构建成功。<br>
运行并查看结果<br>
<img src="https://fujianfei1991.github.io/post-images/1595988078086.png" alt="" loading="lazy"><br>
打开网页查看<br>
<img src="https://fujianfei1991.github.io/post-images/1595988135680.png" alt="" loading="lazy"></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Docker 在 Centos7 安装使用]]></title>
        <id>https://fujianfei1991.github.io/post/docker-zai-centos7-an-zhuang-shi-yong/</id>
        <link href="https://fujianfei1991.github.io/post/docker-zai-centos7-an-zhuang-shi-yong/">
        </link>
        <updated>2020-07-27T03:01:20.000Z</updated>
        <content type="html"><![CDATA[<h4 id="前提条件">前提条件</h4>
<p><code>Docker</code> 运行在 <code>Centos7</code> 上面，对系统内核是有要求的<br>
要求系统为64位，系统内核版本位 <code>3.10</code> 以上</p>
<pre><code># 查看内核版本
[root@izbp1afvt32y9uri4c7x4tz ~]# uname -r
3.10.0-1062.9.1.el7.x86_64
</code></pre>
<h2 id="安装">安装</h2>
<p>** 安装依赖包 **</p>
<pre><code>sudo yum install -y yum-utils device-mapper-persistent-data lvm2 
</code></pre>
<p>** 设置镜像源 **<br>
这里的设置镜像源只是为了安装 <code>Docker</code> 来使用的，与后面的镜像仓库需要区分开来</p>
<pre><code># 采用阿里云镜像源
sudo yum-config-manager --add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo
</code></pre>
<p>** 更新yum **</p>
<pre><code>$ sudo yum update
</code></pre>
<p>** 查看可以安装的Docker版本 **</p>
<pre><code># 如果没有设置上面的镜像源，有可能会没有任何包
$ yum list docker-ce --showduplicates | sort -r
</code></pre>
<p>** 指定版本安装 **</p>
<pre><code>$ yum install docker-ce-18.03.1.ce-1.el7.centos
</code></pre>
<p>** 查看版本 **</p>
<pre><code>[root@izbp1afvt32y9uri4c7x4tz ~]# docker version
Client:
 Version:      18.03.1-ce
 API version:  1.37
 Go version:   go1.9.5
 Git commit:   9ee9f40
 Built:        Thu Apr 26 07:20:16 2018
 OS/Arch:      linux/amd64
 Experimental: false
 Orchestrator: swarm
Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?   # 这里是由于Docker没有运行才会出现这个提醒
</code></pre>
<h2 id="docker-用户设置"><code>Docker</code> 用户设置</h2>
<p>由于<code>Docker</code> 需要运行在<code>root</code>或者<code>docker</code> 这个用户组中的用户下面，所以需要设置一下用户，毕竟使用root运行还是不太合适，考虑到安全性的问题<br>
** 设置用户 **</p>
<pre><code>$ useradd docker   # 添加用户docker
$ passwd docker    # 设置用户docker的密码

# 添加到docker用户组与查看
$ sudo usermod -aG docker npoulton    # 将npoulton用户添加到docker用户组
$ cat /etc/group | grep docker     # 查看操作是否成功
docker:x:999:npoulton
</code></pre>
<h2 id="docker-操作命令"><code>Docker</code> 操作命令</h2>
<pre><code># 启动docker
$ sudo service docker start   # service 命令的用法
$ sudo systemctl start docker     # systemctl 命令的用法
</code></pre>
<pre><code># 重启
$ sudo service docker restart   # service 方式
$ sudo systemctl restart docker   # systemctl 命令的方式
</code></pre>
<h2 id="修改镜像源">修改镜像源</h2>
<p>新版的 Docker 使用 /etc/docker/daemon.json（Linux）<br>
上面的 <code>daemon.json</code> 是镜像配置文件（没有该文件的话，请新建一个）：</p>
<pre><code>{
  &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]
}
</code></pre>
<p>设置好之后需要重启一下服务即可</p>
<pre><code>$ sudo service docker restart
</code></pre>
<h2 id="关于image镜像文件">关于<code>image</code>镜像文件</h2>
<p>这里引用阮一峰微博上面的解释说明</p>
<blockquote>
<p>Docker 把应用程序及其依赖，打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容<br>
器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image<br>
文件，可以生成多个同时运行的容器实例。<br>
image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些<br>
性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形<br>
成你的 image。<br>
image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节<br>
省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别<br>
人的 image 文件进行加工，而不是从零开始制作。<br>
为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub<br>
是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。<br>
** 关于<code>image</code>的部分操作说明 **</p>
</blockquote>
<pre><code># 查找镜像，例如nginx镜像
$ docker search nginx
# 拉取镜像，例如nginx
$ docker pull nginx
# 本地镜像列表查看镜像，例如nginx
$ docker image nginx
# 列出本机所以 image 文件
$ docker image ls
# 删除 image 文件
$ docker image rm [imageName]
</code></pre>
<h2 id="关于容器文件">关于容器文件</h2>
<p>image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。</p>
<pre><code>$ docker ps -a         　　　　　//  列出所有的容器
$ docker stop $IMAGE_ID   　 // 停止容器
$ docker rm  $IMAGE_ID  　　// 删除容器
$ docker ps      // 查看所有正在运行容器
$ docker stop containerId    // containerId 是容器的ID
$ docker ps -a     // 查看所有容器
$ docker ps -a -q    // 查看所有容器ID
$ docker stop $(docker ps -a -q)   // stop停止所有容器
$ docker rm $(docker ps -a -q)     // remove删除所有容器
</code></pre>
<h2 id="基本样例">基本样例</h2>
<blockquote>
<p>以 <code>nginx</code> 为例</p>
</blockquote>
<pre><code># 先拉取nginx
$ docker pull nginx
# 镜像中查看
$ docker images
</code></pre>
<p>** 使用nginx镜像开启nginx应用容器 **</p>
<pre><code># 返回
[root@izbp1afvt32y9uri4c7x4tz ~]# docker run -p 8090:80 -d nginx
25579676e9ee014a1f54cc31816aa871462ba20e3923d86a46227543cae8cb00
</code></pre>
<p>当前容器运行起来之后，我们可以进入到容器当中，查看对应的文件运行以及配置情况</p>
<pre><code># 进入到容器里面
[root@izbp1afvt32y9uri4c7x4tz ~]# docker exec -it 25579676e9ee bash  
root@25579676e9ee:/# 
# 因为当前我的镜像当中没有安装vim之类的编辑器，所以无法直接查看文件配置信息
# 查看配置信息
root@25579676e9ee:/# cd /etc/nginx/conf.d/
root@25579676e9ee:/etc/nginx/conf.d# ls
default.conf
</code></pre>
<blockquote>
<p>然后使用ctrl + p + q退出容器，使用exit的话会让容器停止<br>
因为容器里面文件无法编辑，所以可以复制出来进行编辑<br>
使用专用的复制命令将配置文件复制到宿主机，然后在宿主机进行编辑</p>
</blockquote>
<pre><code># 复制出来
[root@localhost docker]# docker cp 25579676e9ee:/etc/nginx/conf.d/default.conf ./default.conf
# 编辑好的文件再复制到容器当中
[root@localhost docker]# docker cp ./default.conf 25579676e9ee:/etc/nginx/conf.d/default.conf
</code></pre>
<p>进入到容器中，重新载入nginx配置文件</p>
<pre><code>[root@localhost docker]# docker exec -it 25579676e9ee bash
root@3218b3ad4e47:/# service nginx reload
[ ok ] Reloading nginx: nginx.
root@3218b3ad4e47:/#
</code></pre>
<blockquote>
<p>容器启动的时候会涉及到诸多的命令以及参数配置项，参考如下：<br>
https://docs.docker.com/engine/reference/commandline/run/<br>
在启动的时候还可以通过run命令的参数配置很多挂载信息，这里就不再详细说明了，可以参考如下连接：<br>
https://www.cnblogs.com/saneri/p/11799865.html</p>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ElK 安装使用 与 elasticsearch-php 扩展使用]]></title>
        <id>https://fujianfei1991.github.io/post/elasticsearch/</id>
        <link href="https://fujianfei1991.github.io/post/elasticsearch/">
        </link>
        <updated>2020-07-18T02:32:12.000Z</updated>
        <content type="html"><![CDATA[<h2 id="简介">简介</h2>
<p><code>mysql</code> 在5.6以前，只有<code>MySIAM</code>支持全文检索，但是不支持索引，从5.6以后 <code>InnoDB</code> 开始支持全文检索，从5.7.6开始支持中文分词，但是正在在项目上应用的时候还是有很多问题，中文分词不准确，性能不高，数据量不大，因而采用 <code>elasticsearch</code> 这种全文检索插件<br>
<code>Elasticsearch</code> 系列产品对照表</p>
<pre><code>https://www.elastic.co/cn/support/matrix#matrix_compatibility
</code></pre>
<p>在<code>Elasticsearch</code> 当中没有表的概念，对应关系有另外的结构体，对照如下</p>
<table>
<thead>
<tr>
<th>关系型数据库（比如Mysql）</th>
<th>非关系型数据库（Elasticsearch）</th>
</tr>
</thead>
<tbody>
<tr>
<td>数据库 Database</td>
<td>索引 Index</td>
</tr>
<tr>
<td>表 Table</td>
<td>类型 Type</td>
</tr>
<tr>
<td>数据行 Row</td>
<td>文档 Document</td>
</tr>
<tr>
<td>数据列 Column</td>
<td>字段 Field</td>
</tr>
<tr>
<td>约束 Schema</td>
<td>映射 Mapping</td>
</tr>
</tbody>
</table>
<h4 id="原理参考">原理参考</h4>
<pre><code>https://developer.51cto.com/art/201904/594615.htm
https://www.cnblogs.com/dreamroute/p/8484457.html
</code></pre>
<h2 id="安装-elasticsearch">安装 <code>Elasticsearch</code></h2>
<p><code>elasticsearch</code> 是基于 <code>java8</code> 以上的环境安装的，所以需要支持先安装 <code>java8</code></p>
<pre><code># 安装java8
$ yum install java-1.8.0.-openjdk* -y

# 安装 elasticsearch
$ wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.16.zip
$ unzip elasticsearch-5.6.16.zip
$ cd elasticsearch-5.6.16/

# 因为elasticsearch不能在root账户下运行，所以的修改账户
$ useradd  hadoop
$ passwd    hadoop
$ su hadoop

// 目录权限也是有影响的，注意修改目录权限
// 运行 elasticsearch
// elasticsearch当前5.6版本的运行内存是2G，需要跟你自己的系统情况做调整
$ vim config/jvm.options
. . .    # 调整如下两个参数大小
-Xms1g
-Xmx1g
. . .

$ ./elasticsearch
//默认是在端口9200上运行的，所以我们访问这个端口就会返回如下信息
[root@localhost ~]# curl localhost:9200
{
  &quot;name&quot; : &quot;pUVGKF5&quot;,
  &quot;cluster_name&quot; : &quot;elasticsearch&quot;,
  &quot;cluster_uuid&quot; : &quot;YuHh_UCqSGCNn7El3U0DVQ&quot;,
  &quot;version&quot; : {
    &quot;number&quot; : &quot;5.6.16&quot;,
    &quot;build_hash&quot; : &quot;3a740d1&quot;,
    &quot;build_date&quot; : &quot;2019-03-13T15:33:36.565Z&quot;,
    &quot;build_snapshot&quot; : false,
    &quot;lucene_version&quot; : &quot;6.6.1&quot;
  },
  &quot;tagline&quot; : &quot;You Know, for Search&quot;
}
# 至此安装成功
</code></pre>
<blockquote>
<p>Elasticsearch 在使用 supervisor 启动的时候，需要改一下配置文件</p>
</blockquote>
<pre><code># $ES_HOME/config/elasticsearch.yml
network.host: 0.0.0.0
http.port: 9200
transport.host: localhost
transport.tcp.port: 9300
</code></pre>
<p>另外 <code>supervisor</code> 里面的配置如下</p>
<pre><code># elasticsearch.conf
[program:elasticsearch]
command=/usr/local/elasticsearch/bin/elasticsearch
directory=/usr/local/elasticsearch/bin
user=hadoop
numprocs=1
priority=1
autostart=true
startsecs=10
satrtretries=3
autorestart=true
stopasgroup=true
killasgroup=true
redirect_stderr=true
stdout_logfile_maxbytes=50MB
stdout_logfile_backups=10
stdout_logfile=/var/log/supervisor/elasticsearch.out.log
stderr_logfile=/var/log/supervisor/elasticsearch.err.log
</code></pre>
<h2 id="数据同步">数据同步</h2>
<p>历史数据存放在 <code>MySQL</code> 当中就涉及到同步的问题<br>
同步工具由官方提供的 <code>logstash</code> 与 淘宝的 <code>canal</code>，具体的差异这里不做描述了，我这里使用的是 <code>logstash</code></p>
<h4 id="logstash安装">logstash安装</h4>
<p>首先去官方下载对应软件，这个跟 <code>elasticsearch</code> 版本是对应的，所以下载的时候需要看下版本号</p>
<pre><code>// logstash-5.6.16.zip 下载有点慢
$ wget https://artifacts.elastic.co/downloads/logstash/logstash-5.6.16.zip 
$ unzip logstash-5.6.16.zip
// 可以转移到跟 elasticsearch 同级目录，我这里是放在 src目录下面
$ mv logstash-5.6.16 /usr/local/logstash
</code></pre>
<h4 id="安装logstash-输入与输出的插件">安装logstash 输入与输出的插件</h4>
<p>安装 <code>jdbc</code> 和 <code>elasticsearch</code> 插件，这两个插件分别连接 <code>MySQL</code> 与 <code>Elasticsearch</code></p>
<pre><code>$ bin/logstash-plugin install logstash-input-jdbc   // 安装比较慢
$ bin/logstash-plugin install logstash-output-elasticsearch
</code></pre>
<h4 id="安装-mysql-对接到-logstash-的驱动">安装 MySQL 对接到 logstash 的驱动</h4>
<pre><code>$ wget https://cdn.mysql.com//Downloads/Connector-J/mysql-connector-java-5.1.46.zip
$ unzip mysql-connector-java-5.1.46.zip
// 放到 logstash 的config目录里面
$ mv mysql-connector-java-5.1.46 /usr/local/logstash/config/mysql-connector-java
</code></pre>
<p>上面的插件都安装完成之后，需要生成 logstash 对应 <code>MySQL</code> 和 <code>Elasticsearch</code> 的配置文件，配置文件放置在 <code>logstash</code> 的配置文件目录 <code>config</code> 当中，文件名随便取，<code>sync_table.conf</code>，文件内容如下：<br>
ps：这里面涉及到了两个表的信息，所以填写了两个配置信息</p>
<pre><code>input {
  jdbc {
    jdbc_driver_library =&gt; &quot;./config/mysql-connector-java/mysql-connector-java-5.1.46-bin.jar&quot;
    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
    jdbc_connection_string =&gt; &quot;jdbc:mysql://127.0.0.1:3306/yiren&quot;
    jdbc_user =&gt; &quot;root&quot;
    jdbc_password =&gt; &quot;e-line2019&quot;
    schedule =&gt; &quot;* * * * *&quot;
    statement =&gt; &quot;SELECT * FROM task_sales_source WHERE update_time &gt;= :sql_last_value&quot;
    use_column_value =&gt; true
    tracking_column_type =&gt; &quot;timestamp&quot;
    tracking_column =&gt; &quot;update_time&quot;
    clean_run =&gt; false
    last_run_metadata_path =&gt; &quot;last_source_id.txt&quot;
    type =&gt; &quot;task_sales_source&quot;
    tags =&gt; &quot;task_sales_source&quot;
  }
  jdbc {
    jdbc_driver_library =&gt; &quot;./config/mysql-connector-java/mysql-connector-java-5.1.46-bin.jar&quot;
    jdbc_driver_class =&gt; &quot;com.mysql.jdbc.Driver&quot;
    jdbc_connection_string =&gt; &quot;jdbc:mysql://127.0.0.1:3306/yiren&quot;
    jdbc_user =&gt; &quot;root&quot;
    jdbc_password =&gt; &quot;e-line2019&quot;
    schedule =&gt; &quot;* * * * *&quot;
    statement =&gt; &quot;SELECT * FROM task_source_extend WHERE update_time &gt;= :sql_last_value&quot;
    use_column_value =&gt; true
    tracking_column_type =&gt; &quot;timestamp&quot;
    tracking_column =&gt; &quot;update_time&quot;
    clean_run =&gt; false
    last_run_metadata_path =&gt; &quot;last_extend_id.txt&quot;
    type =&gt; &quot;task_source_extend&quot;
    tags =&gt; &quot;task_source_extend&quot;
  }
}

output {
  if [type] == &quot;task_sales_source&quot;{
        elasticsearch {
            hosts =&gt; &quot;127.0.0.1:9200&quot;  
            index =&gt; &quot;task_sales_source&quot;  
            document_id =&gt; &quot;%{id}&quot;
        }
    }
    if [type] == &quot;task_source_extend&quot;{
        elasticsearch {
            hosts =&gt; &quot;127.0.0.1:9200&quot;
            index =&gt; &quot;task_source_extend&quot;  
            document_id =&gt; &quot;%{id}&quot;
        }
    }
  # elasticsearch {
  #   hosts =&gt; [&quot;127.0.0.1:9200&quot;]
  #   index =&gt; &quot;users&quot;
  #   document_id =&gt; &quot;%{id}&quot;
  #   document_type =&gt; &quot;users&quot;
  # }
  stdout {
      codec =&gt; json_lines
  }
}
</code></pre>
<h4 id="以配置文件启动">以配置文件启动</h4>
<pre><code>$ ./bin/logstash -f ./config/sync_table.conf
</code></pre>
<p>这样就可以看到如下的同步记录情况，默认是每分钟同步一次，可以根据自己的情况来设定同步时间<br>
<img src="https://fujianfei1991.github.io/post-images/1595229302517.jpg" alt="" loading="lazy"></p>
<h4 id="时区问题">时区问题</h4>
<p>由于 <code>logstash</code> 本身采取的是 UTC时区，所以需要对获取的时间 +8 小时<br>
在 <code>sync_table.conf</code> 增加如下配置</p>
<pre><code># sync_table.conf
. . .
filter {
  ruby { 
    code =&gt; &quot;event.set('create_time', event.get('create_time').time.localtime + 8*60*60)&quot;
  }
  ruby { 
    code =&gt; &quot;event.set('update_time', event.get('update_time').time.localtime + 8*60*60)&quot;
  }
}
. . .
</code></pre>
<h2 id="kibana-使用">kibana 使用</h2>
<p>借助 <code>kibana</code> 来实现对 <code>Elasticsearch</code> 的数据可视化查看</p>
<h4 id="安装">安装</h4>
<pre><code>$ wget wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.16-linux-x86_64.tar.gz
# 对比数据包，返回hash值，与官网的包文件对比
$ sha1sum kibana-5.6.16-linux-x86_64.tar.gz   
$ tar -xzf kibana-5.6.16-linux-x86_64.tar.gz
$ mv kibana-5.6.16-linux-x86_64 /usr/local/kibana
$ cd /usr/local/kinaba
</code></pre>
<p>这里有一点，需要开启公网访问权限的时候，需要改一下配置文件<code>kibana.yml</code></p>
<pre><code># config/kibana.yml
. . .
$ server.port: 5601
$ server.host: &quot;0.0.0.0&quot;
. . .
</code></pre>
<p>启动</p>
<pre><code>$ ./bin/kibana
</code></pre>
<p>这样就可以在公网上访问<code>kibana</code> 的web管理界面</p>
<h4 id="基础配置">基础配置</h4>
<p>添加 <code>index</code> (添加索引，这里的索引对应的就是MySQL当中的库)<br>
<code>Management</code> =&gt; <code>Index Patterns</code> =&gt; <code>Create Index Pattern</code> =&gt; <code>Index pattern</code> =&gt; <code>Time Filter field name</code> 选择 <code>I don't want to use ths Time Filter</code><br>
查看 <code>Discover</code><br>
<img src="https://fujianfei1991.github.io/post-images/1595230977809.jpg" alt="" loading="lazy"></p>
<h4 id="至此elk全套的安装完成">** 至此，ELK全套的安装完成 **</h4>
<h2 id="elasticsearch-php-安装使用"><code>Elasticsearch-php</code> 安装使用</h2>
<p><code>elasticsearch</code> 官方有支持 PHP 的库，使用 <code>composer</code> 安装就可以直接使用，注意版本需要对照，并且基于PHP7 的环境<br>
对照关系如下</p>
<table>
<thead>
<tr>
<th>Elasticsearch 版本</th>
<th>Elasticsearch-PHP 分支</th>
</tr>
</thead>
<tbody>
<tr>
<td>&gt;= 6.0</td>
<td><code>6.0</code></td>
</tr>
<tr>
<td>&gt;= 5.0, ⇐ 6.0</td>
<td><code>5.0</code></td>
</tr>
<tr>
<td>&gt;= 1.0, ⇐ 5.0</td>
<td><code>1.0</code>, <code>2.0</code></td>
</tr>
<tr>
<td>⇐ 0.90.*</td>
<td><code>0.4</code></td>
</tr>
</tbody>
</table>
<h4 id="composer-安装如下">composer 安装如下</h4>
<pre><code>// 方式一
//compooser.json文件添加如下，在composer update
{
    &quot;require&quot;: {
        &quot;elasticsearch/elasticsearch&quot;: &quot;~6.0&quot;
    }
}

//方式二
//直接运行composer命令行安装
$ composer require elasticsearch/elasticsearch 5.0
</code></pre>
<p>我这边当前是在 ThinkPHP5 框架里面安装的，安装结果就在 <code>vender</code> 里面<br>
这个扩展里面有个函数 <code>filter_var</code> 是已经启用的，所以需要去掉，修改如下：</p>
<pre><code class="language-php"># elasticsearch/elasticsearch/src/Elasticsearch/ClientBuilder.php
. . .
/**
* @param string $host
*
* @return string
*/
private function prependMissingScheme($host)
{
    // if (!filter_var($host, FILTER_VALIDATE_URL, FILTER_FLAG_SCHEME_REQUIRED)) {
    //     $host = 'http://' . $host;
    // }
    if (empty(parse_url($host, PHP_URL_SCHEME))){
        $host = 'http://' . $host;
    }
    return $host;
}
</code></pre>
<p>使用样例：</p>
<pre><code>. . .
use Elasticsearch\ClientBuilder;
. . .
public function search(){
    try{
        $client = ClientBuilder::create()-&gt;build();
        $params = [
            'index' =&gt; 'task_source_extend',
            'type' =&gt; 'task_source_extend',  
        ];        
        $results = $client-&gt;search($params);
        var_dump(json_encode($results,true));
    }catch(\Exception $e){
        var_dump($e-&gt;getMessage());
    }
}
</code></pre>
<p>详细使用说明如下：<code>https://www.elastic.co/guide/cn/elasticsearch/php/current/_search_operations.html</code></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[supervisor 安装使用]]></title>
        <id>https://fujianfei1991.github.io/post/ce-shi/</id>
        <link href="https://fujianfei1991.github.io/post/ce-shi/">
        </link>
        <updated>2020-07-16T09:59:22.000Z</updated>
        <content type="html"><![CDATA[<h2 id="简介">简介</h2>
<p>superviosr是一个Linux/Unix系统上的进程监控工具，他/她upervisor是一个Python开发的通用的进程管理程序，可以管理和监控Linux上面的进程，能将一个普通的命令行进程变为后台daemon，并监控进程状态，异常退出时能自动重启。不过同daemontools一样，它不能监控daemon进程</p>
<h2 id="组件">组件</h2>
<ul>
<li>supervisord<br>
主进程,负责管理进程的server，它会根据配置文件创建指定数量的应用程序的子进程，管理子进程的整个生命周期，对crash的进程重启，对进程变化发送事件通知等。同时内置web server和XML-RPC Interface，轻松实现进程管理。。该服务的配置文件在/etc/supervisor/supervisord.conf</li>
<li>supervisorctl<br>
客户端的命令行工具，提供一个类似shell的操作接口，通过它你可以连接到不同的supervisord进程上来管理它们各自的子程序，命令通过UNIX socket或者TCP来和服务通讯。用户通过命令行发送消息给supervisord，可以查看进程状态，加载配置文件，启停进程，查看进程标准输出和错误输出，远程操作等。服务端也可以要求客户端提供身份验证之后才能进行操作。</li>
<li>web server<br>
superviosr提供了web server功能，可通过web控制进程(需要设置[inet<em>http</em>server]配置项)。</li>
<li>XML-RPC interface<br>
XML-RPC接口， 就像HTTP提供WEB UI一样，用来控制supervisor和由它运行的程序。</li>
</ul>
<h2 id="安装">安装</h2>
<p>当前环境 <code>CentOS Linux release 7.7.1908 (Core)</code><br>
安装方法有多种：1、使用源码安装，2、使用yum安装，3、由于是用python写的，所以还提供一中 pip 安装的方式<br>
​	1、源码安装</p>
<pre><code class="language-sh">wget https://pypi.python.org/packages/source/s/supervisor/supervisor-3.1.3.tar.gz
tar zxvf supervisor-3.1.3.tar.gz
cd supervisor-3.1.3
python setup.py install
</code></pre>
<p>​	2、yum安装</p>
<pre><code class="language-sh">yum install -y supervisor
</code></pre>
<p>​	3、pip安装（我当前的python环境是2.7）</p>
<pre><code class="language-sh">pip install supervisor
</code></pre>
<p>检查是否安装成功，执行如下命令，返回版本号即可</p>
<pre><code class="language-sh">supervisord -v
</code></pre>
<h2 id="基础配置">基础配置</h2>
<p>创建配置文件</p>
<pre><code># echo_supervisord_conf &gt; /etc/supervisord.conf
</code></pre>
<p>基础配置文件一般情况下不需要更改，除了最后的 [include] 部分，其余保持默认即可</p>
<h4 id="子进程配置文件">子进程配置文件</h4>
<p>一般放在：<code>/etc/supervisord.d/</code> 这个目录下面，一个脚本对应一个配置文件<br>
在 <code>/etc/supervisord.conf</code> 当中 [include] 默认没有开启，需要打开一下</p>
<pre><code>. . .
# 开启网页访问
[inet_http_server]         ; inet (TCP) server disabled by default
port=0.0.0.0:9001        ; (ip_address:port specifier, *:port for all iface)
username=user              ; (default is no username (open server))
password=123               ; (default is no password (open server))
. . .
# 这里需要根据自己的情况来设置
[include]
files = /etc/supervisord.d/*.conf
</code></pre>
<p>指定配置文件启动</p>
<pre><code># supervisord -c /etc/supervisord.conf
</code></pre>
<h2 id="配置开机自启">配置开机自启</h2>
<p>编辑服务文件</p>
<pre><code class="language-sh"># vim /usr/lib/systemd/system/supervisord.service

# 内容如下
[Unit]
Description=Supervisor daemon

[Service]
Type=forking
PIDFile=/var/run/supervisord.pid
ExecStart=/usr/bin/supervisord -c /etc/supervisord.conf
ExecStop=/usr/bin/supervisorctl shutdown
ExecReload=/usr/bin/supervisorctl reload
KillMode=process
Restart=on-failure
RestartSec=42s

[Install]
WantedBy=multi-user.target
</code></pre>
<p>启动服务</p>
<pre><code># systemctl enable supervisord
</code></pre>
<p>查看是否启动</p>
<pre><code># systemctl is-enabled supervisord
enabled
</code></pre>
<p>管理 <code>supervisor</code> 服务</p>
<pre><code># systemctl stop supervisord
# systemctl start supervisord
# systemctl status supervisord
# systemctl reload supervisord
# systemctl restart supervisord
</code></pre>
<h2 id="子进程管理">子进程管理</h2>
<p>一般放在：<code>/etc/supervisord.d/</code> 这个目录下面，一个脚本对应一个配置文件<br>
** 配置说明 **</p>
<pre><code>; 应用名称，必填
[program:echo_time]
; 进程执行前会切换到指定目录下执行，默认不切换，非必须
directory = /tmp
; 启动优先级，默认-1
priority = -1
; 子进程操作命令，最后带上完整路径
command=sh /tmp/echo_time.sh
;  子进程是否被自动启动
autostart=true
; 这个是设置子进程挂掉后自动重启的情况，有三个选项，false,unexpected和true。如果为false的时候，无论什么情况下，都不会被重新启动，如果为unexpected，只有当进程的退出码不在下面exitcodes里面定义的退出码的时候，才会被自动重启。当为true的时候，只要子进程挂掉，将会被无条件的重启
autorestart=true
; 子进程启动几秒后被认为启动成功
startsecs=10
; 子进程启动失败后，最大尝试重新启动次数
startretries=3 
; 子进程退出码，注意和上面的autorestart=unexpected 相对应，exitcodes里面定义的退出码是expected 的，关于这个子进程退出码还是需要再了解下
exitcodes=0,2
; 进程停止信号，可以为TERM, HUP, INT, QUIT, KILL, USR1, or USR2 等信号，默认为 TERM，当用设定的信号去干扰进程，退出码会被认为是expected，非必须设置
stopsignal=QUIT
; 当向子进程发送 stopsignal信号后，到系统返回信息给supervisor 所等待的最大时间，超过这个时间，supervisor会向该子进程发送一个强制 kill 的信号，默认 10 秒，非必须设置
stopwaitsecs=10
; 启动的用户
user=root
; 日志开启
log_stdout=true
; 日志错误开启
log_stderr=true
; 子进程日志
logfile=/tmp/echo_time.log
; 单日志文件最大的大小，默认是50M，当超过时会生成一个新的文件，设置为0时表示不限制大小
logfile_maxbytes=1MB
; 日志文件保持的数量，上面的日志文件超过限定时，就会生成一个新的文件，当文件数量大于限制数量时，最初的老文件会被新文件覆盖，文件数量将保持不变，当设置为0时，表示不限制文件的数量，默认为10，非必须设置
logfile_backups=10
 ; stdout日志文件最大的大小，属性同上
stdout_logfile_maxbytes=20MB 
; stdout 日志文件数量，属性同上
stdout_logfile_backups=20 
; stdout 日志文件位置
stdout_logfile=/tmp/echo_time.stdout.log
</code></pre>
<h2 id="使用样例">使用样例</h2>
<p>脚本文件 <code>/tmp/echo_time.sh</code><br>
** 内容如下：**</p>
<pre><code>#/bin/bash
while true; do
    echo `date + %Y-%m-%d,%H:%m:%s`
    sleep 2
done
</code></pre>
<p>在 <code>/etc/supervisor.d</code> 当中新增子进程配置文件 <code>echo_time.conf</code> , 内容如下</p>
<pre><code>[program:echo_time]
command=sh /tmp/echo_time.sh  ; 启动命令
priority=999                ; the relative start priority (default 999)
autostart=true              ; start at supervisord start (default: true)
autorestart=true            ; retstart at unexpected quit (default: true)
startsecs=10                ; number of secs prog must stay running (def. 10)
startretries=3              ; max # of serial start failures (default 3)
exitcodes=0,2               ; 'expected' exit codes for process (default 0,2)
stopsignal=QUIT             ; signal used to kill process (default TERM)
stopwaitsecs=10             ; max num secs to wait before SIGKILL (default 10)
user=root                 ; setuid to this UNIX account to run the program
log_stdout=true
log_stderr=true             ; if true, log program stderr (def false)
logfile=/tmp/echo_time.log
logfile_maxbytes=1MB        ; max # logfile bytes b4 rotation (default 50MB)
logfile_backups=10          ; # of logfile backups (default 10)
stdout_logfile_maxbytes=20MB  ; stdout 日志文件大小，默认 50MB
stdout_logfile_backups=20     ; stdout 日志文件备份数
stdout_logfile=/tmp/echo_time.stdout.log
</code></pre>
<p>保存之后重新启动程序，加载配置信息</p>
<pre><code># supervisorctl reread    # 重新读取配置
# supervisorctl update   # 更新子进程
</code></pre>
<p>执行 <code>update</code> 后输出</p>
<pre><code>echo_time: added process group
</code></pre>
<p>可以通过日志或者<code>supervisorctl status</code> 查看子进程运行情况</p>
<pre><code># supervisorctl  status
echo_time                        RUNNING   pid 5542, uptime 0:00:11
</code></pre>
<p>由于我这边启用了开机自启的服务，所以还可以执行 <code>systemctl status supervisord</code> 查看</p>
<pre><code># systemctl status supervisord
● supervisord.service - Supervisor daemon
   Loaded: loaded (/usr/lib/systemd/system/supervisord.service; enabled; vendor preset: disabled)
   Active: activating (auto-restart) (Result: exit-code) since Fri 2020-07-17 11:29:27 CST; 31s ago
  Process: 5678 ExecStart=/bin/supervisord -c /etc/supervisord.conf (code=exited, status=2)
   CGroup: /system.slice/supervisord.service
           ├─ 5542 sh /tmp/echo_time.sh  # 此处就是子进程的PID
           ├─ 5737 sleep 2
           └─15349 /usr/bin/python /usr/bin/supervisord -c /etc/supervisord.conf
</code></pre>
<p>在网页当中也可以查看到 子进程的状态<br>
<img src="https://fujianfei1991.github.io/post-images/1594966890823.png" alt="" loading="lazy"></p>
<h2 id="supervisor-定期重启指定进程">supervisor 定期重启指定进程</h2>
<p>可以利用 <code>crontab</code> 来实现定期任务，设置如下：</p>
<pre><code>## 假如每天早上6点重启一个进程 aaa，这里的aaa 就是配置在supervisor里面的进程名称
0 6 * * *  supervisorctl -c /etc/supervisord.conf restart aaa
</code></pre>
<p>当对于某些会出现内存泄漏或连接不自动释放的进程时，我们可以使用以上方法进行定期重启，解决内存泄漏及释放连接数。</p>
]]></content>
    </entry>
</feed>